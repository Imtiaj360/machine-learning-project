# -*- coding: utf-8 -*-
"""Copy of CSE422_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sRjSIPdqOJQDPg6fvUt1k9oPl9gZk3rX

# Import
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import  warnings
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder
from sklearn.preprocessing import StandardScaler

# Data moduling
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

"""# Read data"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/Cardiovascular_disease_dataset/heart.csv")
df.head(10)

categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

print("Categorical Columns:")
print(categorical_columns)

print("\nNumerical Columns:")
print(numerical_columns)

"""# Distribution of Numeric columns"""

numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns

fig, axes = plt.subplots(len(numeric_columns) // 3 + 1, 3, figsize=(20, 15))
axes = axes.flatten()

for i, column in enumerate(numeric_columns):
    ax = axes[i]
    df[column].plot(kind='hist', bins=7, ax=ax, alpha=0.9, color= '#1f77b4', edgecolor="white")
    ax.set_title(f"Distribution of {column}", fontsize=14)
    ax.set_xlabel(column, fontsize=12)
    ax.set_ylabel("Count", fontsize=12)
    ax.grid(axis='y', linestyle='--', alpha=0.5)

for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""# Distribution of Categorical columns"""

categorical_columns = [col for col in df.columns if df[col].dtype == 'object']

num_columns = len(categorical_columns)
fig, axes = plt.subplots(1, num_columns, figsize=(4 * num_columns, 5))

if num_columns == 1:
    axes = [axes]

for i, column in enumerate(categorical_columns):
    value_counts = df[column].value_counts()
    sns.barplot(x=value_counts.index, y=value_counts.values, palette='viridis', ax=axes[i])
    axes[i].set_title(f"Distribution of {column}", fontsize=16)
    axes[i].set_xlabel(column, fontsize=12)
    axes[i].set_ylabel("Count", fontsize=12)
    axes[i].tick_params(axis='x', rotation=45, labelsize=10)
    axes[i].tick_params(axis='y', labelsize=10)
    axes[i].grid(axis='y', linestyle='--', alpha=0.3)

plt.tight_layout()
plt.show()

"""# Null values in the dataset"""

df.isna().sum()

sns.heatmap(df.isna())

"""# Handling null values"""

# Handling missing values of neumerical variables
df['Age'].fillna(df['Age'].mean(), inplace=True)
df['RestingBP'].fillna(df['RestingBP'].median(), inplace=True)
df['Cholesterol'].fillna(df['Cholesterol'].mean(), inplace=True)
df['Oldpeak'].fillna(df['Oldpeak'].median(), inplace=True)
df['MaxHR'].fillna(df['MaxHR'].mean(), inplace=True)
df['FastingBS'].fillna(df['FastingBS'].mode()[0], inplace=True)

# Handle missing values of categorical variables
df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)
df['ChestPainType'].fillna(df['ChestPainType'].mode()[0], inplace=True)
df['RestingECG'].fillna(df['RestingECG'].mode()[0], inplace=True)

df.isna().sum()

sns.heatmap(df.isna())

# Data describing
df.describe()

"""# Handling categorical values"""

#lebel encoding for column "Sex"
label_sex = LabelEncoder()
df['Sex'] = label_sex.fit_transform(df['Sex'])

#One hot encoding for column "ChestPainType"
df = pd.get_dummies(df, columns=['ChestPainType'], prefix='ChestPainType', drop_first=False)

#One hot encoding for column "RestingECG"
df = pd.get_dummies(df, columns=['RestingECG'], prefix='RestingECG', drop_first=False)

#lebel encoding for column "ExerciseAngina"
label_exercise_angina = LabelEncoder()
df['ExerciseAngina'] = label_exercise_angina.fit_transform(df['ExerciseAngina'])

# ordinal encoding for column "ST_Slope"
ordinal_st_slope = OrdinalEncoder(categories=[['Up', 'Flat', 'Down']])
df['ST_Slope'] = ordinal_st_slope.fit_transform(df[['ST_Slope']])

# boolean to integer
df = df.astype({col: int for col in df.select_dtypes(include='bool').columns})

df.shape

"""# Correlation between features"""

correlation = df.corr()
correlation
plt.figure(figsize = (15,7))
sns.heatmap(correlation, annot = True, cmap = "coolwarm")

df.head()



"""# Distribution of all columns after encoding

"""

df.hist(figsize=(20,15))
plt.show()

"""# Feature scaling : Robust scaler"""

from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
numerical_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

df.head()

df.head(10)

from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression

"""#Model applying

## Logistic regression
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

y_pred = lr_model.predict(X_test)

print("Logistic Regression:")
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap="Blues", values_format='d')
plt.title("Logistic Regression Confusion Matrix")
plt.show()

"""## Random forest classifier"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

print("Random Forest:")
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap="Blues", values_format='d')
plt.title("Random Forest Confusion Matrix")
plt.show()

"""## Naive bayes"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

y_pred = nb_model.predict(X_test)

print("Naive Bayes:")
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap="Blues", values_format='d')
plt.title("Naive Bayes Confusion Matrix")
plt.show()

"""## Neural network"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)

y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob >= 0.5).astype(int).flatten()

print("Neural Network:")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap="Blues", values_format='d')
plt.title("Neural Network Confusion Matrix")
plt.show()

import matplotlib.pyplot as plt

# Example accuracy scores from the models (Replace with actual values)
model_accuracies = {
    "Logistic Regression": 0.85,
    "Random Forest": 0.88,
    "Naive Bayes": 0.83,
    "Neural Network": 0.88
}

# Extract model names and accuracy scores
model_names = list(model_accuracies.keys())
accuracies = list(model_accuracies.values())

# Plot the bar chart
plt.figure(figsize=(10, 6))
plt.bar(model_names, accuracies, color="skyblue", edgecolor="black")
plt.title("Model Accuracy Comparison", fontsize=16)
plt.xlabel("Models", fontsize=14)
plt.ylabel("Accuracy", fontsize=14)
plt.ylim(0, 1)  # Accuracy ranges from 0 to 1
plt.xticks(rotation=45, fontsize=12)
plt.yticks(fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Display values on top of each bar
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 0.02, f"{acc:.2f}", ha='center', fontsize=12)

plt.tight_layout()
plt.show()